+ 用途

    基于一定的语料库，预估或评估一个句子是否合理<br>
    评估2个字符串之间的差异，模糊匹配中的常用手段
    
## n-gram语法
一种统计语言模型的算法，其基本思想是对文本内容按照字节进行大小为n的窗口滑动操作，形成长度为n的字节片段序列。（窗口滑动属于TCP知识，参见博文：https://blog.csdn.net/u011904605/article/details/53033255） 
+ 一个假设-马尔科夫假设
> 一个词出现的概率仅仅依赖于他前面出现的有限个的一个或多个单词。第n个词的出现只与他前面的n-1个词有关，而与其他词没有关系。整个句子出现的概率为每个词出现每个词受前一个影响出现的概率的乘积。

s为一个有意义的句子，由一串特定顺序排列的词（w1w2……wi）组成，i表示字符串的长度，即s的单词个数，则s在整个语料库中出现的可能性p(s)，依据链式法则可分解为：

    p（s）=p（w1）p（w2|w1）……p（wi|wi-1）
    当n=1时，为一元模型
    当n=2是，为二元模型
    n=3是，为三元模型
    n指的是字节片段的长度，当n越小时，模型只考虑临近词语之间的关系；当n越大时，模型更多考虑更长距离的上下文之间的关联关系。
    每一个字节片段是一个gram，对所有出现的gram出现的频度进行统计，按照事先设定好的阈值进行过滤，形成关键gram列表，即该文本的向量特征空间，文本中的每一种gram就是一个特征向量维度。
    
## 使用最大似然估计，计算每一项的条件概率
+ 归一化
对于概率模型来说，归一化指，用某个总数来除，是最后得到的概率的值处于0和1之间，以保持概率的合法性。
+ 极大似然估计（maximum likelihood estimation）
极大似然估计通过计算字节片段在语料库中出现的频数，预估单词wi出现在第i位置的概率。它认为，在句子s中，单词wi出现在 以n为字节片段的 第i位的概率可以表示为：

    p（wi|w1w2……wi-1）=c（w1w2……wi）/c（w1w2……wi-1）

+ 2个缺陷
随着n的增大，模型需要的参数变多，导致参数空间过大。
① 参数空间过大；<br>②数据稀疏严重
## 平滑技术
+ add-one平滑    

取二元语法的计数矩阵，在归一化之前，给所有计数加一。
add-delta平滑    
good-turning打折法
