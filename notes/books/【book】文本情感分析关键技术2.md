## 第三章 网络挖掘的数据获取
* 网络数据挖掘<br>
从大量的数据中通过**算法**搜索隐藏于其中信息的过程。
* 网络目录挖掘<br>
从网页内容中提取/挖掘信息或知识。
* 网络使用挖掘<br>
从网络使用日志中发现用户访问模式。
### 第一部分 数据挖掘基础
#### 一 万维网介绍
* HTTP，hyper text transfer protocol 超文本传输协议
>从www服务器传输超文本到本地浏览器的传送协议。一个应用层协议，有请求和相应构成，一个标砖的客户端-服务器模型。
* HTML，超文本标记语言
>是标准通用标记语言下的一个应用，通过标记符号来标记要显示的网页中的各个部分。浏览器按顺序阅读网页文件，根据标记符解释和显示其标记的内容，对书写出的标记
不指出其错误，不停止其解释执行过程，编织者只能通过显示效果来分析出错愿意和出错部位。
* URL,统一资源定位符
>对 可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网哈桑标准资源的地址。每个文件对应唯一的URL。使用ASCII代码的一部分表示互联网的地址。
* TCP/IP,transmission control protocol/internet protocol,网络通信协议。
### 第二部分 网络挖掘
**网络挖掘步骤**
* 前处理<br>
抽样、归类、特征选择
* 数据挖掘<br>
算法
* 后处理<br>

**网络数据挖掘的内容**<br>
*信息抓取（web crawling）*<br>
自动遍历网页的超链接结构，病将每个连接页面下载到本地存储的程序。将非结构化的信息从网站中抓取出来，保存早结构化的数据库中的过程。
*结构化数据的提取：包装器生成（wrapper generation）*
跟随固定模板从底层数据库卡检索出来显示在网页中的数据记录被称为 结构化数据。提取方法有 监督提取和无监督提取。
*意见挖掘和情绪分析*
挖掘在产品评论、论坛讨论和博客上的意见和情绪。

## 第四章 中文分词
### 第一节 自然语言处理
#### 目前英文文本理解步骤：
* 预处理
对字符进行处理，去掉不处理的字符
>符号化，tokenization，学术文献中的定义：1，将实际问题转化为数学问题，并建立数学模型。2，对于指令、指令地址、常熟、变量等，在屏幕上均用表义性和可读性很强的的符号来显示。还有其他定义，由于过于抽象或者 与本主题关系不大，略去。
* 语法分析
采用分析器，即parser对句子进行分析。改进分析器，增强其适应性。进行*词性标注*。
* 语义分析
* 含义表示
>与英文文本处理不同的是，在对中文语法分析之前，必须进行**分词**。对于文本理解的每一个步骤都需要分别进行细致深入的研究，早期使用的技术主要基于**自动机理论**，后来概率算法逐渐融入，信息论的互信息、最大熵用来解决言单位间的内聚性。<br>
*最大熵类似于 投资领域的不要把鸡蛋放在同一个篮子里的风险降低 策略，其主要思想是：在只掌握关于未知分布的的部分知识时，应 选取符合这些知识 但熵值最大的 概率分布。熵，实际上定义的是 一个随机变量的不确定性，熵最大的时候，说明随机变量最不确定。也就是说，随机变量越随机，对其行为做准确预测最困难。**最大熵原理的实质就是，在已知部分知识的前提下，关于未知分布最合理的推断，就是符合已知知识最不确定或最随机的推断。*
#### 无监督分词研究

* 研究方法
