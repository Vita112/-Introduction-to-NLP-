 一种基于深度学习的实体关系抽取方法及应用  周亚林  浙大硕士论文 2018年
 ## 1.abstract
 提出2种基于深度学习的关系抽取方法：
 >①BLSTM + Attention + 浅层句法特征和实体特征
 >②使用word level CNN 和 character level CNN，抽取句子特征，结合2种结果进行预测
 对deepdive关系抽取工具进行二次开发，在原有数据基础上，加入数据增量处理、基于深度学习的训练、预测模块。
 
 
 ## 2.先行研究
 从 实体关系分类、实体和关系联合抽取、开放式关系抽取 3方面介绍。
 ### 2.1 实体间关系分类
 pipeline task：先抽取句子中的实体，再对实体对的关系进行分类

+ 基于特征向量的方法——从实体对的上下文中抽取`词语、词性、实体类别、最短依赖路径`等特征，训练分类器进行分类
>研究者有：Kambhatla使用实体本身 实体类型 句法解析树等，训练最大熵模型(ME)进行关系分类；Zhou提取更多句法解析树；
>Sun提出基于词语聚类的特征抽取方法，选择聚类效果较好的词语集合进行分类
+ 基于树核函数的方法——定义核函数，在句子的浅层句法分析上计算2个句子的相似度，使用SVM进行关系分类。
>研究者有：Bunescu提出基于`最短依存句法路径`的核函数，计算2个句子在依存句法路径上的`相同词语个数`，来计算`句子相似度`；
>Zhang提出`卷积树核函数`，提取蕴含在句法树中的`句法信息`。
+ 基于深度学习的方法
```
socher提出矩阵-向量递归神经网络(MV-RNN)来捕捉句子中复杂的语义信息。
zeng将词语、词语的相对位置特征作为输入，使用CNN提取sentence level的特征，结合entity context和wordnet上位词语等特征。
santos提出基于排序的CNN模型，为每个类别定义一个标准特征向量，同CNN生成的句子特征向量做内积，内积最大的类作为最终预测结果。
xu先假设：依存关系树中2个实体间最短路径上的词语描述了这2个实体间的关系，然后使用CNN对最短路径上的文本提取特征，并分类。
yan提出在最短依存路径上使用LSTM模型，将路径上的词语、pos tagging、语法关系、wordnet上位词作为输入。
```
attention注意力机制应用于关系抽取，提出端到端的模型。
```
zhou 将句子中的词语作为输入，使用BLSTM处理后的输出，作为Attention的输入，再次处理。
wang 使用2层注意力机制的 CNN 模型，首先为每一个类别定义一个特征向量，使用2个实体 对输入句子中的词语 进行1次attention；然后用CNN对句子进行特征抽取，
对 抽取结果使用 类别特征向量进行 第2层attention。
```
distance supervision远程监督方法
>mintz 使用distance supervision 生成带噪音的标注数据集，在极短时间内生成大量标注样本，缓解数据不足的问题。**对于噪音标注问题**，<br>
zeng 提出了multi-instance的 nn模型，在训练时，对于每个实体对，只选取最能反映其关系的句子来训练。<br>
lin 在 sentence level上使用 attention，对同一对实体的不同句子 分配 不同的权重，减少噪音样本的影响。
### 2.2 实体和关系联合抽取——参数共享和标注策略
+ zheng 使用BLSTM对句子进行编码，分别使用一个LSTM进行NER，一个CNN进行关系分类，分类时根据NER的结果选取实体对。模型共享底层的BLSTM。
+ miwa 同时使用BLSTM(用于实体检测)和树状LSTM(用于关系抽取)对句子进行建模，2者参数共享。


 
 
 
 
